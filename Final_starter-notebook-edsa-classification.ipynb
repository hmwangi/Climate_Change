{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import the necessary libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n\nfrom sklearn.metrics import f1_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":82,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load in your data from kaggle.  \nBy working in a kaggle kernel, you can access the data directly from the competition, as well as make your submission without downloading your output file"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/climate-change-edsa2020-21/train.csv')\ntest = pd.read_csv('../input/climate-change-edsa2020-21/test.csv')","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sentiment.value_counts()","execution_count":84,"outputs":[{"output_type":"execute_result","execution_count":84,"data":{"text/plain":" 1    8530\n 2    3640\n 0    2353\n-1    1296\nName: sentiment, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['message'] = train['message'].str.lower()","execution_count":85,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['message']  = train['message'] .str.replace('\\d+', '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['message'] = train['message'].str.replace('&amp','&')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['message'] = train['message'].str.replace('rt','')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['message'] = train['message'].str.replace(\"[^a-zA-Z#]\", \" \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['message'] = train['message'].str.replace('#','')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from nltk.tokenize import word_tokenize, TreebankWordTokenizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tokeniser = TreebankWordTokenizer()\n\n#combine['Tidy_Tweets'] = combine['Tidy_Tweets'].apply(tokeniser.tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\n#stemmer = PorterStemmer()\n#def climate_stemmer(words, stemmer):\n#    return [stemmer.stem(word) for word in words]\n#train['message'] = train['message'].apply(climate_stemmer, args=(stemmer, ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from nltk.stem import WordNetLemmatizer\n#nltk.download('wordnet')\n#lemmatizer = WordNetLemmatizer()\n#train['message'] = train['message'].apply(climate_lemma, args=(lemmatizer, ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from nlppreprocess import NLP\n#nlp = NLP()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def cleaner(line):\n\n#    punctuation = re.compile(\"[.;:!\\'’‘“”?,\\\"()\\[\\]]\")\n#    tweet = punctuation.sub(\"\", line.lower()) \n    # Removes stopwords\n#    nlp_for_stopwords = NLP(replace_words=True, remove_stopwords=True, \n#                            remove_numbers=True, remove_punctuations=False) \n#    tweet = nlp_for_stopwords.process(tweet) \n\n#    return tweet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#combine['Tidy_Tweets'] = combine['message'].apply(cleaner)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def remove_symbols(tweet, pattern):\n#    r = re.findall(pattern, tweet)\n#    for i in r:\n#        tweet = re.sub(i, '', tweet)\n        \n#    return tweet","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['message'] = np.vectorize(remove_symbols)(train['message'], \"@[\\w]*\") ","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"   sentiment                                            message  tweetid\n0          1  polyscimajor epa chief doesn't think carbon di...   625221\n1          1  it's not like we lack evidence of anthropogeni...   126103\n2          2  rt : researchers say we have three years to ac...   698562\n3          1  #todayinmaker# wired : 2016 was a pivotal year...   573736\n4          1  rt : it's 2016, and a racist, sexist, climate ...   466954","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>polyscimajor epa chief doesn't think carbon di...</td>\n      <td>625221</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>it's not like we lack evidence of anthropogeni...</td>\n      <td>126103</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>rt : researchers say we have three years to ac...</td>\n      <td>698562</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n      <td>573736</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>rt : it's 2016, and a racist, sexist, climate ...</td>\n      <td>466954</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['message'] = train['message'].str.replace(\"[^a-zA-Z#]\", \" \")","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.utils import resample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pro = train[train['sentiment']==1]\n#anti = train[train['sentiment']==-1]\n#neutral = train[train['sentiment']==0]\n#news = train[train['sentiment']==2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"anti_upsampled = resample(anti,\n                          replace=True, # sample with replacement (we need to duplicate observations)\n                          n_samples=len(pro), # match number in minority class\n                          random_state=27) # reproducible results\n\nneutral_upsampled = resample(neutral,\n                             replace=True, # sample with replacement (we need to duplicate observations)\n                             n_samples=len(pro), # match number in minority class\n                             random_state=27) # reproducible results\n\nnews_upsampled = resample(news,\n                          replace=True, # sample with replacement (we need to duplicate observations)\n                          n_samples=len(pro), # match number in minority class\n                          random_state=27) # reproducible results\n\n# Combine upsampled minority class with majority class\nupsampled = pd.concat([anti_upsampled, neutral_upsampled,news_upsampled,pro])\n\n# Check new class counts\nupsampled.sentiment.value_counts()\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting out the X variable from the target"},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train['sentiment']\nX = train['message']","execution_count":86,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Turning text into something your model can read"},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=2, stop_words=\"english\")\nX_vectorized = vectorizer.fit_transform(X)","execution_count":87,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Splitting the training data into a training and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=.20,shuffle=True, stratify=y, random_state=1)","execution_count":88,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training the model and evaluating using the validation set "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC(kernel='linear')\nsvc.fit(X_train, y_train)\nsvc_pred = svc.predict(X_val)","execution_count":89,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking the performance of our model on the validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"f1_score(y_val, svc_pred, average=\"macro\")","execution_count":90,"outputs":[{"output_type":"execute_result","execution_count":90,"data":{"text/plain":"0.6695910675639931"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Getting our test set ready "},{"metadata":{"trusted":true},"cell_type":"code","source":"testx = test['message']\ntest_vect = vectorizer.transform(testx)","execution_count":91,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making predictions on the test set and adding a sentiment column to our original test df"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = svc.predict(test_vect)","execution_count":92,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sentiment'] = y_pred","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":94,"outputs":[{"output_type":"execute_result","execution_count":94,"data":{"text/plain":"                                             message  tweetid  sentiment\n0  Europe will now be looking to China to make su...   169760          1\n1  Combine this with the polling of staffers re c...    35326          1\n2  The scary, unimpeachable evidence that climate...   224985          1\n3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263          1\n4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>message</th>\n      <th>tweetid</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Europe will now be looking to China to make su...</td>\n      <td>169760</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Combine this with the polling of staffers re c...</td>\n      <td>35326</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The scary, unimpeachable evidence that climate...</td>\n      <td>224985</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n      <td>476263</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n      <td>872928</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Creating an output csv for submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['tweetid','sentiment']].to_csv('testsubmission7.csv', index=False)","execution_count":78,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}